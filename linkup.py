import streamlit as st
import streamlit.components.v1 as components
import httpx
import requests
import asyncio
import re
import time
import random
import string
import json
import threading
import uuid
import html
from urllib.parse import quote
from datetime import datetime, timedelta, timezone
from retrying import retry

# ==========================================
# 0. å…¨å±€é…ç½®ä¸å·¥å…·
# ==========================================
st.set_page_config(page_title="ç½‘ç›˜è½¬å­˜åŠ©æ‰‹", page_icon="ğŸ“‚", layout="wide")

st.markdown("""
    <style>
    /* æ‰‹æœºç«¯æ—¥å¿—ä¼˜åŒ– */
    .log-container {
        font-family: 'Menlo', monospace; font-size: 12px;
        border: 1px solid #e0e0e0; border-radius: 8px;
        padding: 5px; background: #fafafa;
        max-height: 300px; overflow-y: auto;
    }
    .log-item { display: flex; align-items: flex-start; padding: 4px 0; border-bottom: 1px solid #f0f0f0; }
    .log-time { color: #999; font-size: 11px; margin-right: 8px; min-width: 55px; }
    .log-msg { color: #333; word-break: break-all; }
    .smart-link { background: #e6f7ff; color: #1890ff; padding: 0 4px; border-radius: 3px; font-size: 11px; }
    
    /* çŠ¶æ€ç‚¹ */
    .status-dot-green { color:#52c41a; margin-right:4px; }
    .status-dot-gray { color:#d9d9d9; margin-right:4px; }
    </style>
""", unsafe_allow_html=True)

# åŸºç¡€å¸¸é‡
QUARK_SAVE_PATH = "æ¥è‡ªï¼šåˆ†äº«/LinkChanger"
BAIDU_SAVE_PATH = "/æˆ‘çš„èµ„æº/LinkChanger"

# ==========================================
# 1. æ ¸å¿ƒï¼šåå°ä»»åŠ¡ç®¡ç†å™¨
# ==========================================
@st.cache_resource
class JobManager:
    def __init__(self):
        self.jobs = {} 

    def _cleanup_old_jobs(self):
        now = datetime.now()
        expired_ids = [jid for jid, job in self.jobs.items() 
                       if (now - job['created_at']).total_seconds() > 86400]
        for jid in expired_ids:
            del self.jobs[jid]

    def create_job(self):
        self._cleanup_old_jobs()
        job_id = str(uuid.uuid4())[:8]
        self.jobs[job_id] = {
            "status": "running", "logs": [], "result_text": "",
            "progress": {"current": 0, "total": 0},
            "created_at": datetime.now(), "summary": {}
        }
        return job_id

    def get_job(self, job_id):
        return self.jobs.get(job_id)

    def add_log(self, job_id, message, type="info"):
        if job_id in self.jobs:
            timestamp = (datetime.now(timezone.utc) + timedelta(hours=8)).strftime("%H:%M:%S")
            self.jobs[job_id]["logs"].append({"time": timestamp, "msg": html.escape(message), "type": type})

    def update_progress(self, job_id, current, total):
        if job_id in self.jobs:
            self.jobs[job_id]["progress"] = {"current": current, "total": total}

    def complete_job(self, job_id, final_text, summary):
        if job_id in self.jobs:
            self.jobs[job_id]["status"] = "done"
            self.jobs[job_id]["result_text"] = final_text
            self.jobs[job_id]["summary"] = summary

job_manager = JobManager()

# ==========================================
# 2. å¼•æ“ç±» (å‡çº§ï¼šå¹¿å‘Šç¼“å­˜ + è‡ªåŠ¨ç›®å½•)
# ==========================================
class QuarkEngine:
    def __init__(self, cookies: str):
        self.headers = {
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'cookie': cookies, 'referer': 'https://pan.quark.cn/'
        }
        self.client = httpx.AsyncClient(timeout=45.0, headers=self.headers, follow_redirects=True)
        # âœ¨ æ–°å¢ï¼šç¼“å­˜æ¤å…¥æ–‡ä»¶çš„ä¿¡æ¯
        self.inject_cache = None

    async def close(self): await self.client.aclose()
    def _params(self): return {'pr': 'ucpro', 'fr': 'pc', '__dt': random.randint(100, 9999), '__t': int(time.time() * 1000)}

    async def check_login(self):
        try:
            r = await self.client.get('https://pan.quark.cn/account/info', params=self._params())
            data = r.json()
            if (data.get('code') == 0 or data.get('code') == 'OK') and data.get('data'):
                return data['data'].get('nickname', 'ç”¨æˆ·')
        except: pass
        return None

    async def _mkdir(self, name, pdir_fid):
        try:
            data = {"file_name": name, "pdir_fid": pdir_fid, "dir_init_lock": False}
            r = await self.client.post('https://drive-pc.quark.cn/1/clouddrive/file/mkdir', json=data, params=self._params())
            if r.json().get('code') == 0: return r.json()['data']['fid']
        except: pass
        return None

    async def ensure_path(self, path: str):
        parts = path.split('/')
        curr_id = '0'
        for part in parts:
            if not part: continue
            found_fid = None
            params = self._params()
            params.update({'pdir_fid': curr_id, '_page': 1, '_size': 50, '_fetch_total': 'false'})
            try:
                r = await self.client.get('https://drive-pc.quark.cn/1/clouddrive/file/sort', params=params)
                for item in r.json().get('data', {}).get('list', []):
                    if item['file_name'] == part and item['dir']:
                        found_fid = item['fid']; break
            except: pass
            
            if not found_fid: found_fid = await self._mkdir(part, curr_id)
            if not found_fid: return None
            curr_id = found_fid
        return curr_id

    async def process_url(self, url: str, target_fid: str, is_inject: bool = False):
        # âœ¨ ç¼“å­˜é€»è¾‘ï¼šå¦‚æœæ˜¯æ¤å…¥æ¨¡å¼ï¼Œä¸”ç¼“å­˜æœ‰æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨
        if is_inject and self.inject_cache:
            source_fids = self.inject_cache['fids']
            source_tokens = self.inject_cache['tokens']
            pwd_id = self.inject_cache['pwd_id']
            stoken = self.inject_cache['stoken']
        else:
            # --- æ­£å¸¸è”ç½‘è§£ææµç¨‹ ---
            try:
                pwd_id = url.split('/s/')[-1].split('?')[0].split('#')[0]
                match = re.search(r'[?&]pwd=([a-zA-Z0-9]+)', url)
                passcode = match.group(1) if match else ""
                
                r = await self.client.post("https://drive-pc.quark.cn/1/clouddrive/share/sharepage/token", 
                                         json={"pwd_id": pwd_id, "passcode": passcode}, params=self._params())
                stoken = r.json().get('data', {}).get('stoken')
                if not stoken: return None, "æå–ç å¤±æ•ˆ", None
                
                params = self._params()
                params.update({"pwd_id": pwd_id, "stoken": stoken, "pdir_fid": "0", "_page": 1, "_size": 50})
                r = await self.client.get("https://drive-pc.quark.cn/1/clouddrive/share/sharepage/detail", params=params)
                items = r.json().get('data', {}).get('list', [])
                if not items: return None, "ç©ºåˆ†äº«", None
                
                source_fids = [i['fid'] for i in items]
                source_tokens = [i['share_fid_token'] for i in items]
                
                # âœ¨ å¦‚æœæ˜¯æ¤å…¥æ¨¡å¼ï¼Œè§£ææˆåŠŸåå†™å…¥ç¼“å­˜
                if is_inject:
                    self.inject_cache = {
                        'fids': source_fids, 'tokens': source_tokens, 
                        'pwd_id': pwd_id, 'stoken': stoken
                    }
            except: return None, "è§£æå¼‚å¸¸", None

        # --- é€šç”¨è½¬å­˜æµç¨‹ ---
        try:
            save_data = {"fid_list": source_fids, "fid_token_list": source_tokens, 
                         "to_pdir_fid": target_fid, "pwd_id": pwd_id, "stoken": stoken, "pdir_fid": "0", "scene": "link"}
            r = await self.client.post("https://drive.quark.cn/1/clouddrive/share/sharepage/save", json=save_data, params=self._params())
            if r.json().get('code') not in [0, 'OK']: return None, f"è½¬å­˜å¤±è´¥: {r.json().get('message')}", None
            task_id = r.json().get('data', {}).get('task_id')
            
            if is_inject: return "INJECT_OK", "æ¤å…¥æˆåŠŸ", None

            # æ­£å¸¸æ–‡ä»¶éœ€è¦ç­‰å¾…å®Œæˆå¹¶åˆ†äº«
            for _ in range(8):
                await asyncio.sleep(1)
                try:
                    params = self._params(); params['task_id'] = task_id
                    r = await self.client.get("https://drive-pc.quark.cn/1/clouddrive/task", params=params)
                    if r.json().get('data', {}).get('status') == 2: break
                except: pass
            
            await asyncio.sleep(1.5)
            new_fid = None
            first_name = items[0]['file_name'] if 'items' in locals() else "Unknown" # itemsåªåœ¨éç¼“å­˜æ—¶æœ‰ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
            
            # å¦‚æœèµ°äº†ç¼“å­˜ï¼Œitemså¯èƒ½æ²¡å®šä¹‰ï¼Œéœ€è¦é‡æ–°å¤„ç†ä¸‹åå­—é€»è¾‘ï¼Œ
            # ä½†ä¸»æµç¨‹process_url(is_inject=False)ä¸ä¼šèµ°ç¼“å­˜ï¼Œæ‰€ä»¥itemsä¸€å®šæœ‰ã€‚
            # åªæœ‰is_inject=Trueæ‰ä¼šèµ°ç¼“å­˜ï¼Œè€Œæ¤å…¥æ¨¡å¼ç›´æ¥è¿”å›INJECT_OKï¼Œä¸éœ€è¦ä¸‹é¢åˆ†äº«é€»è¾‘ã€‚
            
            params = self._params(); params.update({'pdir_fid': target_fid, '_page': 1, '_size': 20, '_sort': 'updated_at:desc'})
            try:
                r = await self.client.get('https://drive-pc.quark.cn/1/clouddrive/file/sort', params=params)
                for item in r.json().get('data', {}).get('list', []):
                    if item['file_name'] == first_name: new_fid = item['fid']; break
                if not new_fid and r.json().get('data', {}).get('list'): new_fid = r.json()['data']['list'][0]['fid']
            except: pass
            
            if not new_fid: return None, "å·²å­˜å…¥ä½†æ— æ³•åˆ†äº«", None
            
            share_data = {"fid_list": [new_fid], "title": first_name, "url_type": 1, "expired_type": 1}
            r = await self.client.post("https://drive-pc.quark.cn/1/clouddrive/share", json=share_data, params=self._params())
            share_task_id = r.json().get('data', {}).get('task_id')
            await asyncio.sleep(0.5)
            params = self._params(); params.update({'task_id': share_task_id})
            r = await self.client.get("https://drive-pc.quark.cn/1/clouddrive/task", params=params)
            share_id = r.json().get('data', {}).get('share_id')
            r = await self.client.post("https://drive-pc.quark.cn/1/clouddrive/share/password", json={"share_id": share_id}, params=self._params())
            return r.json()['data']['share_url'], "æˆåŠŸ", new_fid
        except Exception as e: return None, f"å¼‚å¸¸: {str(e)[:20]}", None

class BaiduEngine:
    def __init__(self, cookies: str):
        self.s = requests.Session()
        self.headers = {'User-Agent': 'Mozilla/5.0', 'Referer': 'https://pan.baidu.com', 'Cookie': cookies}
        self.bdstoken = ''
        # âœ¨ æ–°å¢ï¼šç¼“å­˜
        self.inject_cache = None
        requests.packages.urllib3.disable_warnings()

    def update_cookie(self, bdclnd):
        self.headers['Cookie'] += f'; BDCLND={bdclnd}'

    @retry(stop_max_attempt_number=2)
    def init_token(self):
        try:
            r = self.s.get('https://pan.baidu.com/api/gettemplatevariable', params={'fields': '["bdstoken"]'}, headers=self.headers, verify=False)
            if r.json().get('errno') == 0: self.bdstoken = r.json()['result']['bdstoken']; return True
        except: pass
        return False

    def check_dir_exists(self, path):
        try:
            r = self.s.get('https://pan.baidu.com/api/list', params={'dir': path, 'bdstoken': self.bdstoken, 'start': 0, 'limit': 1}, headers=self.headers, verify=False)
            return r.json().get('errno') == 0
        except: return False

    def create_dir(self, path):
        try:
            self.s.post('https://pan.baidu.com/api/create', params={'a': 'commit', 'bdstoken': self.bdstoken}, 
                        data={'path': path, 'isdir': 1, 'block_list': '[]'}, headers=self.headers, verify=False)
        except: pass

    def process_url(self, url_info: dict, root_path: str, is_inject: bool = False):
        # âœ¨ ç¼“å­˜é€»è¾‘
        if is_inject and self.inject_cache:
            shareid = self.inject_cache['shareid']
            uk = self.inject_cache['uk']
            fs_id_list_str = self.inject_cache['fsidlist'] # å·²ç»æ˜¯å­—ç¬¦ä¸²æ ¼å¼ "[123,456]"
            # ç›´æ¥è·³åˆ° Transfer æ­¥éª¤
        else:
            # --- æ­£å¸¸è”ç½‘è§£æ ---
            try:
                url, pwd = url_info['url'], url_info['pwd']
                clean_url = url.split('?')[0]
                
                if pwd:
                    surl = re.search(r'(?:surl=|/s/1|/s/)([\w\-]+)', clean_url)
                    if not surl: return None, "URLæ ¼å¼é”™è¯¯", None
                    r = self.s.post('https://pan.baidu.com/share/verify', params={'surl': surl.group(1), 't': int(time.time()*1000), 'bdstoken': self.bdstoken, 'channel': 'chunlei', 'web': 1, 'clienttype': 0}, data={'pwd': pwd, 'vcode': '', 'vcode_str': ''}, headers=self.headers, verify=False)
                    if r.json()['errno'] == 0: self.update_cookie(r.json()['randsk'])
                    else: return None, "æå–ç é”™è¯¯", None

                content = self.s.get(clean_url, headers=self.headers, verify=False).text
                fs_id_list = re.findall(r'"fs_id":(\d+?),', content)
                if not fs_id_list: return None, "æ— æ–‡ä»¶", None
                
                shareid = re.search(r'"shareid":(\d+?),', content).group(1)
                uk = re.search(r'"share_uk":"(\d+?)",', content).group(1)
                fs_id_list_str = f"[{','.join(fs_id_list)}]"
                
                # âœ¨ å†™å…¥ç¼“å­˜
                if is_inject:
                    self.inject_cache = {
                        'shareid': shareid, 'uk': uk, 'fsidlist': fs_id_list_str
                    }
            except Exception as e: return None, f"å¼‚å¸¸: {str(e)[:20]}", None

        # --- è½¬å­˜é€»è¾‘ ---
        try:
            if is_inject: save_path = root_path
            else:
                folder_name = url_info.get('name', 'Res')
                safe_suffix = ''.join(random.choices(string.ascii_letters + string.digits, k=4))
                final_folder = f"{folder_name}_{safe_suffix}"
                save_path = f"{root_path}/{final_folder}"
                self.create_dir(save_path) 

            r = self.s.post('https://pan.baidu.com/share/transfer', 
                            params={'shareid': shareid, 'from': uk, 'bdstoken': self.bdstoken}, 
                            data={'fsidlist': fs_id_list_str, 'path': save_path}, 
                            headers=self.headers, verify=False, timeout=20)
            
            if r.json().get('errno') == 12 and is_inject: return "INJECT_OK", "å·²å­˜åœ¨", save_path
            if r.json().get('errno') != 0: return None, f"è½¬å­˜å¤±è´¥({r.json().get('errno')})", None

            if is_inject: return "INJECT_OK", "æˆåŠŸ", save_path

            # åˆ†äº«
            r = self.s.get('https://pan.baidu.com/api/list', params={'dir': root_path, 'bdstoken': self.bdstoken}, headers=self.headers, verify=False)
            target_fsid = None
            for item in r.json().get('list', []):
                if item['server_filename'] == final_folder: target_fsid = item['fs_id']; break
            
            if not target_fsid: return None, "è·å–æ–‡ä»¶å¤±è´¥", None
            new_pwd = ''.join(random.choices(string.ascii_letters + string.digits, k=4))
            r = self.s.post('https://pan.baidu.com/share/set', params={'bdstoken': self.bdstoken, 'channel': 'chunlei', 'clienttype': 0, 'web': 1}, data={'period': 0, 'pwd': new_pwd, 'fid_list': f'[{target_fsid}]', 'schannel': 4}, headers=self.headers, verify=False)
            if r.json()['errno'] == 0: return f"{r.json()['link']}?pwd={new_pwd}", "æˆåŠŸ", save_path 
            return None, "åˆ†äº«å¤±è´¥", None

        except Exception as e: return None, f"å¼‚å¸¸: {str(e)[:20]}", None

# ==========================================
# 3. Worker çº¿ç¨‹ (å‡çº§ï¼šçŸ­é“¾è§£æ)
# ==========================================
def send_notification(bark_key, pushdeer_key, title, body):
    if bark_key:
        url = f"https://api.day.app/{bark_key}/{quote(title)}/{quote(body)}?icon=https://cdn-icons-png.flaticon.com/512/2991/2991110.png"
        try: requests.get(url, timeout=5)
        except: pass
    if pushdeer_key:
        url = "https://api2.pushdeer.com/message/push"
        params = {"pushkey": pushdeer_key, "text": title, "desp": body, "type": "markdown"}
        try: requests.get(url, params=params, timeout=5)
        except: pass

# âœ¨ æ–°å¢ï¼šçŸ­é“¾æ¥è§£æåŠ©æ‰‹
async def resolve_short_links(text):
    # åŒ¹é…éç½‘ç›˜åŸŸåçš„ http/https é“¾æ¥
    # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªå®½æ³›çš„æ­£åˆ™ï¼Œç„¶åæ’é™¤æ‰æˆ‘ä»¬å·²çŸ¥çš„é•¿é“¾æ¥åŸŸå
    urls = list(re.finditer(r'(https?://[^\s,;"\'\)]+)', text))
    if not urls: return text
    
    replacements = {}
    
    async def resolve_one(short_url):
        # å¦‚æœå·²ç»æ˜¯å¤¸å…‹æˆ–ç™¾åº¦ï¼Œè·³è¿‡
        if "pan.quark.cn" in short_url or "pan.baidu.com" in short_url:
            return
        
        try:
            # ä½¿ç”¨ HEAD è¯·æ±‚è·å–çœŸå®åœ°å€ï¼Œç¦æ­¢é‡å®šå‘è·Ÿè¸ªæ¥è·å–Locationï¼Œæˆ–è€…å¼€å¯è·Ÿè¸ªè·å–æœ€ç»ˆURL
            async with httpx.AsyncClient(verify=False, timeout=5.0) as client:
                resp = await client.head(short_url, follow_redirects=True)
                long_url = str(resp.url)
                # åªæœ‰è§£æå‡ºäº†æœ‰æ•ˆç½‘ç›˜é“¾æ¥æ‰æ›¿æ¢
                if "pan.quark.cn" in long_url or "pan.baidu.com" in long_url:
                    replacements[short_url] = long_url
        except:
            pass # è§£æå¤±è´¥åˆ™ä¿ç•™åŸæ ·

    # å¹¶å‘è§£æ
    tasks = [resolve_one(m.group(1)) for m in urls]
    if tasks:
        await asyncio.gather(*tasks)
    
    # æ›¿æ¢æ–‡æœ¬
    new_text = text
    for short, long in replacements.items():
        new_text = new_text.replace(short, long)
        
    return new_text

def worker_thread(job_id, input_text, quark_cookie, baidu_cookie, bark_key, pushdeer_key, inject_config):
    async def async_worker():
        # âœ¨ 1. å…ˆè¿›è¡ŒçŸ­é“¾è§£æ
        job_manager.add_log(job_id, "æ­£åœ¨æ‰«æé“¾æ¥...", "info")
        final_text = await resolve_short_links(input_text)
        
        success_count = 0
        
        q_matches = list(re.finditer(r'(https://pan\.quark\.cn/s/[a-zA-Z0-9]+(?:\?pwd=[a-zA-Z0-9]+)?)', final_text))
        b_matches = list(re.finditer(r'(https?://pan\.baidu\.com/s/[a-zA-Z0-9_\-]+(?:\?pwd=[a-zA-Z0-9]+)?)', final_text))
        total_tasks = len(q_matches) + len(b_matches)
        
        if total_tasks == 0:
            job_manager.add_log(job_id, "æœªæ£€æµ‹åˆ°æœ‰æ•ˆç½‘ç›˜é“¾æ¥", "error")
        
        job_manager.update_progress(job_id, 0, total_tasks)
        q_engine = QuarkEngine(quark_cookie) if q_matches else None
        b_engine = BaiduEngine(baidu_cookie) if b_matches else None

        try:
            # å¤¸å…‹å¤„ç†
            if q_matches and quark_cookie:
                job_manager.add_log(job_id, "æ­£åœ¨ç™»å½•å¤¸å…‹...", "quark")
                user = await q_engine.check_login()
                if not user: job_manager.add_log(job_id, "å¤¸å…‹ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥Cookie", "error")
                else:
                    job_manager.add_log(job_id, f"å¤¸å…‹ç™»å½•æˆåŠŸ: {user}", "success")
                    root_fid = await q_engine.ensure_path(QUARK_SAVE_PATH)
                    for i, match in enumerate(q_matches):
                        job_manager.update_progress(job_id, i+1, total_tasks)
                        raw_url = match.group(1)
                        new_url, msg, new_fid = await q_engine.process_url(raw_url, root_fid)
                        if new_url:
                            final_text = final_text.replace(raw_url, new_url)
                            job_manager.add_log(job_id, f"âœ… {new_url}", "success")
                            success_count += 1
                            if inject_config['quark']['enabled'] and new_fid:
                                # âœ¨ ç¼“å­˜ä¼šåœ¨ process_url å†…éƒ¨è‡ªåŠ¨å¤„ç†
                                await q_engine.process_url(inject_config['quark']['url'], new_fid, is_inject=True)
                        else:
                            job_manager.add_log(job_id, f"âŒ {msg}", "error")
                        await asyncio.sleep(2)

            # ç™¾åº¦å¤„ç†
            if b_matches and baidu_cookie:
                job_manager.add_log(job_id, "æ­£åœ¨ç™»å½•ç™¾åº¦...", "baidu")
                if not b_engine.init_token(): job_manager.add_log(job_id, "ç™¾åº¦ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥Cookie", "error")
                else:
                    job_manager.add_log(job_id, f"ç™¾åº¦ç™»å½•æˆåŠŸ", "success")
                    if not b_engine.check_dir_exists(BAIDU_SAVE_PATH): b_engine.create_dir(BAIDU_SAVE_PATH)
                    start_idx = len(q_matches)
                    for i, match in enumerate(b_matches):
                        job_manager.update_progress(job_id, start_idx+i+1, total_tasks)
                        raw_url = match.group(0)
                        pwd = re.search(r'pwd=([a-zA-Z0-9]{4})', raw_url)
                        pwd = pwd.group(1) if pwd else ""
                        name = f"Res_{int(time.time())}"
                        new_url, msg, new_path = b_engine.process_url({'url': raw_url, 'pwd': pwd, 'name': name}, BAIDU_SAVE_PATH)
                        if new_url:
                            final_text = final_text.replace(raw_url, new_url)
                            job_manager.add_log(job_id, f"âœ… {new_url}", "success")
                            success_count += 1
                            if inject_config['baidu']['enabled'] and new_path:
                                # âœ¨ ç¼“å­˜ä¼šåœ¨ process_url å†…éƒ¨è‡ªåŠ¨å¤„ç†
                                b_engine.process_url({'url': inject_config['baidu']['url'], 'pwd': inject_config['baidu']['pwd']}, new_path, is_inject=True)
                        else:
                            job_manager.add_log(job_id, f"âŒ {msg}", "error")
                        time.sleep(2)

        finally:
            if q_engine: await q_engine.close()
            job_manager.complete_job(job_id, final_text, {"success": success_count, "total": total_tasks})
            if bark_key or pushdeer_key:
                send_notification(bark_key, pushdeer_key, "è½¬å­˜ç»“æŸ", f"æˆåŠŸ: {success_count}/{total_tasks}")

    asyncio.run(async_worker())

# ==========================================
# 4. ä¸»é€»è¾‘ (Secrets + Magic Link)
# ==========================================
def get_user_from_secrets(uid):
    """ä» Secrets çš„ [users] èŠ‚ç‚¹è¯»å–ç”¨æˆ·é…ç½®"""
    try:
        if "users" in st.secrets:
            return st.secrets["users"].get(uid, None)
    except: pass
    return None

def smart_shorten_url(text):
    return re.sub(r'(https?://[^\s]+)', r'<span class="smart-link">LINK</span>', text)

def create_copy_button_html(text):
    safe_text = json.dumps(text)[1:-1]
    return f"""<button onclick="navigator.clipboard.writeText('{safe_text}')" style="width:100%;padding:8px;border:1px solid #ddd;border-radius:4px;background:#fff;cursor:pointer;">ğŸ“‹ ç‚¹å‡»å¤åˆ¶ç»“æœ</button>"""

def main():
    query_params = st.query_params
    uid = query_params.get("uid", None)
    job_id = query_params.get("job_id", None)
    
    # çŠ¶æ€ A: æ¸¸å®¢æ¨¡å¼
    if not uid:
        st.title("â˜ï¸ ç½‘ç›˜è½¬å­˜åŠ©æ‰‹")
        st.info("ğŸ‘‹ æ¬¢è¿ï¼æ­¤ä¸ºå†…éƒ¨å·¥å…·ã€‚")
        st.warning("âš ï¸ è¯·ä½¿ç”¨ç®¡ç†å‘˜ä¸‹å‘çš„ **ä¸“å±é“¾æ¥** (ä¾‹å¦‚ `?uid=xxx`) è®¿é—®ã€‚")
        st.stop()

    # çŠ¶æ€ B: èº«ä»½éªŒè¯
    user_data = get_user_from_secrets(uid)
    if not user_data:
        st.error(f"â›” **è®¿é—®æ‹’ç»**ï¼šæ— æ•ˆçš„ç”¨æˆ· ID `{uid}`")
        st.stop()

    current_name = user_data.get('name', 'User')
    q_cookie = user_data.get('q', '')
    b_cookie = user_data.get('b', '')
    user_bark = user_data.get('bark', '')         
    user_pushdeer = user_data.get('pushdeer', '') 
    
    user_q_img = user_data.get('q_img', '')
    user_b_img = user_data.get('b_img', '')
    user_b_pwd = user_data.get('b_pwd', '')
    
    inject_config = {
        "quark": {"url": user_q_img, "enabled": bool(user_q_img)},
        "baidu": {"url": user_b_img, "pwd": user_b_pwd, "enabled": bool(user_b_img)}
    }

    # çŠ¶æ€ C: æ­£å¸¸åŠŸèƒ½
    st.title(f"ç½‘ç›˜è½¬å­˜ - {current_name}")
    
    with st.expander("ğŸ”Œ è´¦å·ä¸é…ç½®çŠ¶æ€", expanded=False):
        c1, c2 = st.columns(2)
        c1.markdown(f"**å¤¸å…‹**: {'<span class=status-dot-green>â—</span>å·²è¿æ¥' if q_cookie else '<span class=status-dot-gray>â—</span>æœªé…ç½®'}", unsafe_allow_html=True)
        c2.markdown(f"**ç™¾åº¦**: {'<span class=status-dot-green>â—</span>å·²è¿æ¥' if b_cookie else '<span class=status-dot-gray>â—</span>æœªé…ç½®'}", unsafe_allow_html=True)
        
        c3, c4 = st.columns(2)
        has_push = bool(user_bark or user_pushdeer)
        c3.markdown(f"**æ¶ˆæ¯æ¨é€**: {'<span class=status-dot-green>â—</span>å¼€å¯' if has_push else '<span class=status-dot-gray>â—</span>å…³é—­'}", unsafe_allow_html=True)
        has_inject = bool(user_q_img or user_b_img)
        c4.markdown(f"**å¹¿å‘Šæ¤å…¥**: {'<span class=status-dot-green>â—</span>å¼€å¯' if has_inject else '<span class=status-dot-gray>â—</span>å…³é—­'}", unsafe_allow_html=True)

    if not job_id:
        if not q_cookie and not b_cookie:
            st.error("æ‚¨å°šæœªé…ç½®ä»»ä½•ç½‘ç›˜ Cookieï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚")
        else:
            input_text = st.text_area("ğŸ“ ç²˜è´´é“¾æ¥...", height=150, placeholder="æ”¯æŒçŸ­é“¾æ¥ã€å¤¸å…‹ã€ç™¾åº¦ç½‘ç›˜é“¾æ¥æ··åˆç²˜è´´")
            if st.button("ğŸš€ å¼€å§‹è½¬å­˜", type="primary", use_container_width=True):
                if not input_text.strip(): st.toast("è¯·è¾“å…¥å†…å®¹"); return
                
                new_job_id = job_manager.create_job()
                t = threading.Thread(target=worker_thread, args=(
                    new_job_id, input_text, q_cookie, b_cookie, 
                    user_bark, user_pushdeer, inject_config
                ))
                t.start()
                
                st.query_params["job_id"] = new_job_id
                st.query_params["uid"] = uid 
                st.rerun()

    else:
        job = job_manager.get_job(job_id)
        if not job:
            st.warning("ä»»åŠ¡å·²è¿‡æœŸæˆ–ä¸å­˜åœ¨")
            if st.button("ğŸ”™ è¿”å›"):
                st.query_params["uid"] = uid; st.rerun()
        else:
            status = job['status']
            if status == "running":
                st.info("ğŸ”„ æ­£åœ¨å¤„ç†ä¸­...")
                prog = job['progress']
                if prog['total'] > 0: st.progress(prog['current']/prog['total'])
            else:
                st.success("âœ… å¤„ç†å®Œæˆï¼")

            with st.container():
                st.markdown('<div class="log-container">', unsafe_allow_html=True)
                for log in job['logs']:
                    msg = smart_shorten_url(log['msg'])
                    st.markdown(f'<div class="log-item"><div class="log-time">{log["time"]}</div><div class="log-msg">{msg}</div></div>', unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)
            
            if status == "done":
                res = job['result_text']
                st.text_area("ç»“æœ", value=res, height=150)
                components.html(create_copy_button_html(res), height=60)
                if st.button("ğŸ—‘ï¸ å¼€å§‹æ–°ä»»åŠ¡", use_container_width=True):
                    st.query_params.clear(); st.query_params["uid"] = uid; st.rerun()
            else:
                time.sleep(2); st.rerun()

if __name__ == "__main__":
    main()
