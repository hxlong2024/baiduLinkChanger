import streamlit as st
import requests
from retrying import retry
import time
import re
import random
import string
import traceback
from typing import Union, List, Any

# ==========================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šé…ç½®ä¸å¸¸é‡
# ==========================================

BASE_URL = 'https://pan.baidu.com'
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',
    'Referer': 'https://pan.baidu.com',
}

# ä¸¥æ ¼çš„éæ³•å­—ç¬¦æ­£åˆ™ï¼šé™¤äº† æ±‰å­—ã€å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€æ¨ªçº¿ã€ç©ºæ ¼ ä»¥å¤–çš„å…¨éƒ¨è§†ä¸ºéæ³•
INVALID_CHARS_REGEX = re.compile(r'[^\u4e00-\u9fa5a-zA-Z0-9_\-\s]')


# ==========================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒå·¥å…·å‡½æ•°
# ==========================================

def sanitize_filename(name: str) -> str:
    """
    å¼ºåŠ›æ¸…æ´—æ–‡ä»¶å
    åªä¿ç•™ï¼šä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€æ¨ªçº¿ã€ç©ºæ ¼
    å»é™¤ï¼šEmojiã€ç‰¹æ®Šç¬¦å·(ã€ã€‘[]()...)ã€æ§åˆ¶ç¬¦ç­‰
    """
    if not name: return ""
    # æ›¿æ¢å¸¸è§å¹²æ‰°ç¬¦ä¸ºç©ºæ ¼
    name = re.sub(r'[ã€ã€‘\[\]()]', ' ', name)
    # æ›¿æ¢æ‰€æœ‰éç™½åå•å­—ç¬¦ä¸ºç©ºå­—ç¬¦ä¸²
    clean_name = INVALID_CHARS_REGEX.sub('', name)
    # å°†è¿ç»­ç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ªï¼Œå¹¶å»é™¤é¦–å°¾ç©ºæ ¼
    clean_name = re.sub(r'\s+', ' ', clean_name).strip()
    return clean_name


def extract_folder_name(full_text: str, match_start: int) -> str:
    """æ™ºèƒ½æå–æ–‡ä»¶å¤¹åç§°"""
    lookback_limit = max(0, match_start - 200)
    pre_text = full_text[lookback_limit:match_start]
    lines = pre_text.splitlines()

    candidate_name = ""
    for line in reversed(lines):
        clean_line = line.strip()
        if not clean_line: continue
        # è·³è¿‡çº¯æç¤ºè¯è¡Œ
        if re.match(r'^(ç™¾åº¦|é“¾æ¥|æå–ç |:|ï¼š|https?|å¤¸å…‹)*$', clean_line, re.IGNORECASE):
            continue

        # ç§»é™¤è¡Œå†…çš„å¹²æ‰°è¯
        clean_line = re.sub(r'(ç™¾åº¦|é“¾æ¥|æå–ç |:|ï¼š|pwd|å¤¸å…‹).*$', '', clean_line, flags=re.IGNORECASE).strip()

        if clean_line:
            candidate_name = clean_line
            break

    # æ¸…æ´—åå­—
    final_name = sanitize_filename(candidate_name)

    # å¦‚æœæ¸…æ´—ååå­—å¤ªçŸ­æˆ–ä¸ºç©ºï¼Œè¿”å›None(æŒ‡ç¤ºåç»­ä½¿ç”¨é»˜è®¤å)
    if not final_name or len(final_name) < 2:
        return None

    return final_name[:50]  # æˆªæ–­é•¿åº¦


def clean_quark_links(text: str) -> str:
    """å‰”é™¤å¤¸å…‹ç½‘ç›˜é“¾æ¥åŠå…¶æ•´è¡Œ"""
    return re.sub(r'^.*pan\.quark\.cn.*$[\r\n]*', '', text, flags=re.MULTILINE)


def update_cookie(bdclnd: str, cookie: str) -> str:
    cookies_dict = dict(map(lambda item: item.split('=', 1), filter(None, cookie.split(';'))))
    cookies_dict['BDCLND'] = bdclnd
    return ';'.join([f'{key}={value}' for key, value in cookies_dict.items()])


def generate_code() -> str:
    return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(4))


def parse_response(content: str) -> Union[List[Any], int]:
    try:
        content_str = content.decode("utf-8")
    except:
        content_str = str(content)

    shareid = re.search(r'"shareid":(\d+?),', content_str)
    uk = re.search(r'"share_uk":"(\d+?)",', content_str)
    fs_id = re.findall(r'"fs_id":(\d+?),', content_str)

    if shareid and uk and fs_id:
        return [shareid.group(1), uk.group(1), fs_id, [], []]
    return -1


# ==========================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šç½‘ç»œè¯·æ±‚ç±»
# ==========================================

class Network:
    def __init__(self):
        self.s = requests.Session()
        self.s.trust_env = False
        self.headers = HEADERS.copy()
        self.bdstoken = ''
        requests.packages.urllib3.disable_warnings()

    @retry(stop_max_attempt_number=3, wait_fixed=2000)
    def get_bdstoken(self) -> Union[str, int]:
        url = f'{BASE_URL}/api/gettemplatevariable'
        params = {'fields': '["bdstoken","token","uk","isdocuser"]'}
        try:
            r = self.s.get(url, params=params, headers=self.headers, verify=False)
            if 'errno' in r.json() and r.json()['errno'] != 0:
                return r.json()['errno']
            return r.json()['result']['bdstoken']
        except:
            return -1

    @retry(stop_max_attempt_number=3)
    def verify_pass_code(self, link: str, code: str) -> Union[str, int]:
        url = f'{BASE_URL}/share/verify'
        surl = re.search(r'(?:surl=|/s/1|/s/)([\w\-]+)', link)
        if not surl: return -9

        params = {
            'surl': surl.group(1),
            't': str(int(time.time() * 1000)),
            'bdstoken': self.bdstoken,
            'channel': 'chunlei', 'web': '1', 'clienttype': '0'
        }
        data = {'pwd': code, 'vcode': '', 'vcode_str': ''}
        r = self.s.post(url, params=params, data=data, headers=self.headers, verify=False)
        if r.json()['errno'] == 0:
            return r.json()['randsk']
        return r.json()['errno']

    def get_transfer_params(self, url: str) -> bytes:
        return self.s.get(url, headers=self.headers, verify=False).content

    @retry(stop_max_attempt_number=3)
    def create_dir(self, path: str) -> int:
        url = f'{BASE_URL}/api/create'
        data = {'path': path, 'isdir': '1', 'block_list': '[]'}
        params = {'a': 'commit', 'bdstoken': self.bdstoken}
        r = self.s.post(url, params=params, data=data, headers=self.headers, verify=False)
        return r.json()['errno']

    @retry(stop_max_attempt_number=5)
    def transfer_file(self, params_list: list, path: str) -> int:
        url = f'{BASE_URL}/share/transfer'
        data = {'fsidlist': f"[{','.join(params_list[2])}]", 'path': f'/{path}'}
        params = {'shareid': params_list[0], 'from': params_list[1], 'bdstoken': self.bdstoken}
        r = self.s.post(url, params=params, data=data, headers=self.headers, verify=False)
        return r.json()['errno']

    @retry(stop_max_attempt_number=3)
    def create_share(self, fs_id: str, pwd: str) -> Union[str, int]:
        url = f'{BASE_URL}/share/set'
        data = {'period': '0', 'pwd': pwd, 'fid_list': f'[{fs_id}]', 'schannel': '4'}
        params = {'bdstoken': self.bdstoken, 'channel': 'chunlei', 'clienttype': '0', 'web': '1'}
        r = self.s.post(url, params=params, data=data, headers=self.headers, verify=False)
        if r.json()['errno'] == 0:
            return r.json()['link']
        return r.json()['errno']

    def get_dir_fsid(self, parent_path: str, target_name: str) -> str:
        url = f'{BASE_URL}/api/list'
        params = {'dir': parent_path, 'bdstoken': self.bdstoken, 'order': 'time', 'desc': '1'}
        r = self.s.get(url, params=params, headers=self.headers, verify=False)
        if r.json()['errno'] == 0:
            for item in r.json()['list']:
                if item['server_filename'] == target_name:
                    return item['fs_id']
        return None


# ==========================================
# ç¬¬å››éƒ¨åˆ†ï¼šStreamlit ä¸šåŠ¡æµç¨‹
# ==========================================

def process_single_link(network, match, full_text, root_path):
    url = match.group(1)

    # 1. æå–æå–ç 
    pwd_match = re.search(r'(?:\?pwd=|&pwd=|\s+|æå–ç [:ï¼š]?\s*)([a-zA-Z0-9]{4})', match.group(0))
    pwd = pwd_match.group(1) if pwd_match else ""
    clean_url = url.split('?')[0]

    # 2. æ™ºèƒ½æå–æ–‡ä»¶å¤¹å (å«ä¸¥æ ¼æ¸…æ´—)
    folder_name = extract_folder_name(full_text, match.start())
    # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ—¶é—´æˆ³å
    if not folder_name:
        folder_name = f"Resource_{int(time.time())}"
        st.write(f"âš ï¸ æ— æ³•æå–æœ‰æ•ˆåç§°ï¼Œä½¿ç”¨é»˜è®¤å: **{folder_name}**")
    else:
        st.write(f"ğŸ“‚ è¯†åˆ«å¹¶å‡€åŒ–èµ„æºåä¸º: **{folder_name}**")

    # 3. éªŒè¯é“¾æ¥
    if pwd:
        res = network.verify_pass_code(clean_url, pwd)
        if isinstance(res, int):
            st.error(f"âŒ é“¾æ¥éªŒè¯å¤±è´¥ ({clean_url}) é”™è¯¯ä»£ç : {res}")
            return None
        network.headers['Cookie'] = update_cookie(res, network.headers['Cookie'])

    # 4. è·å–å‚æ•°
    content = network.get_transfer_params(clean_url)
    params = parse_response(content)
    if params == -1:
        st.error(f"âŒ é“¾æ¥è§£æå¤±è´¥ ({clean_url}) - å¯èƒ½æ˜¯æ­»é“¾æˆ–Cookieè¿‡æœŸ")
        return None

    # 5. åˆ›å»ºæ–‡ä»¶å¤¹ & è½¬å­˜ (æ ¸å¿ƒä¿®å¤é€»è¾‘ï¼šå¤±è´¥é‡è¯•æœºåˆ¶)

    # å°è¯•ä¸€ï¼šä½¿ç”¨æå–çš„åå­— + éšæœºç 
    safe_suffix = generate_code()
    final_folder_name = f"{folder_name}_{safe_suffix}"
    full_save_path = f"{root_path}/{final_folder_name}"

    network.create_dir(root_path)  # ç¡®ä¿æ ¹ç›®å½•å­˜åœ¨

    create_res = network.create_dir(full_save_path)

    # å¦‚æœåˆ›å»ºå¤±è´¥ï¼ˆä¸”ä¸æ˜¯å› ä¸ºæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼‰ï¼Œåˆ™é™çº§å°è¯•
    if create_res != 0 and create_res != -8:
        st.warning(f"âš ï¸ ä½¿ç”¨åç§° '{final_folder_name}' åˆ›å»ºç›®å½•å¤±è´¥ (ä»£ç : {create_res})ï¼Œå°è¯•ä½¿ç”¨å®‰å…¨æ—¶é—´æˆ³åç§°...")

        # å°è¯•äºŒï¼šå®Œå…¨å®‰å…¨çš„çº¯æ—¶é—´æˆ³åç§°
        final_folder_name = f"Transfer_{int(time.time())}_{safe_suffix}"
        full_save_path = f"{root_path}/{final_folder_name}"
        create_res_retry = network.create_dir(full_save_path)

        if create_res_retry != 0 and create_res_retry != -8:
            st.error(f"âŒ ç›®å½•åˆ›å»ºå½»åº•å¤±è´¥ (ä»£ç : {create_res_retry})ï¼Œè·³è¿‡æ­¤ä»»åŠ¡ã€‚")
            return None
        st.write(f"âœ… å·²åˆ‡æ¢ä¸ºå®‰å…¨ç›®å½•å: {final_folder_name}")

    # æ‰§è¡Œè½¬å­˜
    transfer_res = network.transfer_file(params, full_save_path)
    if transfer_res != 0:
        st.error(f"âŒ è½¬å­˜æ–‡ä»¶å¤±è´¥ (ä»£ç : {transfer_res}) - è¯·æ£€æŸ¥ç½‘ç›˜ç©ºé—´æˆ–æ–‡ä»¶æ•°é‡é™åˆ¶")
        return None

    # 6. åˆ†äº«
    fs_id = network.get_dir_fsid(f"/{root_path}", final_folder_name)
    if not fs_id:
        st.error("âŒ è½¬å­˜åæ— æ³•è·å–æ–‡ä»¶å¤¹IDï¼Œæ— æ³•åˆ†äº«")
        return None

    new_pwd = generate_code()
    share_link = network.create_share(fs_id, new_pwd)

    if isinstance(share_link, int):
        st.error(f"âŒ åˆ›å»ºåˆ†äº«é“¾æ¥å¤±è´¥ (ä»£ç : {share_link})")
        return None

    st.success(f"âœ… å¤„ç†æˆåŠŸï¼")
    return f"{share_link}?pwd={new_pwd}"


# å›è°ƒå‡½æ•°ï¼šæ¸…é™¤æ–‡æœ¬æ¡†çŠ¶æ€
def clear_text():
    st.session_state["user_input"] = ""


def main():
    st.set_page_config(page_title="ç™¾åº¦ç½‘ç›˜è½¬å­˜åŠ©æ‰‹", layout="wide")
    st.title("ğŸ”„ ç™¾åº¦ç½‘ç›˜æ™ºèƒ½è½¬å­˜ (ä¿®å¤ç‰ˆ)")

    with st.sidebar:
        cookie = st.text_area("è¾“å…¥Cookie (å¿…å¡«)", height=150)
        root_path = st.text_input("ç½‘ç›˜ä¿å­˜è·¯å¾„", value="æˆ‘çš„è‡ªåŠ¨è½¬å­˜èµ„æº")

    # æ–‡æœ¬æ¡†ç»‘å®š key="user_input"ï¼Œä»¥ä¾¿åœ¨ session_state ä¸­ç®¡ç†
    input_text = st.text_area(
        "ğŸ“ è¾“å…¥æ–‡æœ¬",
        height=200,
        placeholder="ç²˜è´´åŒ…å«é“¾æ¥çš„æ–‡æœ¬ï¼Œç¨‹åºå°†è‡ªåŠ¨å‡€åŒ–æ–‡ä»¶åå¹¶è½¬å­˜...",
        key="user_input"
    )

    # æŒ‰é’®å¸ƒå±€ï¼šä¸€é”®æ¸…é™¤ ä¸ å¼€å§‹å¤„ç†
    col1, col2 = st.columns([1, 6])

    with col1:
        st.button("ğŸ—‘ï¸ ä¸€é”®æ¸…é™¤", on_click=clear_text)

    with col2:
        start_process = st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary")

    if start_process:
        if not cookie:
            st.warning("è¯·å…ˆè¾“å…¥ Cookie")
            st.stop()

        # 1. é¢„å¤„ç†
        processed_text = clean_quark_links(input_text)

        network = Network()
        network.headers['Cookie'] = "".join(cookie.split())

        with st.status("æ­£åœ¨è‡ªåŠ¨åŒ–å¤„ç† (ç‚¹å‡»å±•å¼€è¯¦æƒ…)...", expanded=True) as status:
            token = network.get_bdstoken()
            if isinstance(token, int):
                status.update(label=f"âŒ Cookie æ— æ•ˆ (ä»£ç : {token})", state="error")
                st.stop()
            network.bdstoken = token

            link_regex = re.compile(r'(https?://pan\.baidu\.com/s/[a-zA-Z0-9_\-]+(?:\?pwd=[a-zA-Z0-9]+)?)')
            matches = list(link_regex.finditer(processed_text))

            if not matches:
                status.update(label="âš ï¸ æœªæ‰¾åˆ°ç™¾åº¦ç½‘ç›˜é“¾æ¥", state="complete")
                st.stop()

            final_text = processed_text
            success_count = 0

            # å€’åºå¤„ç†
            for match in reversed(matches):
                st.divider()  # åˆ†éš”çº¿
                new_link = process_single_link(network, match, processed_text, root_path)
                if new_link:
                    start, end = match.span()
                    final_text = final_text[:start] + new_link + final_text[end:]
                    success_count += 1

            if success_count > 0:
                status.update(label=f"âœ… å…¨éƒ¨å®Œæˆï¼æˆåŠŸå¤„ç† {success_count} ä¸ªé“¾æ¥", state="complete")
            else:
                status.update(label="âš ï¸ å¤„ç†å®Œæˆï¼Œä½†æ²¡æœ‰æˆåŠŸè½¬å­˜ä»»ä½•é“¾æ¥", state="error")

        if success_count > 0:
            st.subheader("ğŸ‰ å¤„ç†ç»“æœ (ç‚¹å‡»å³ä¸Šè§’å¤åˆ¶)")
            st.code(final_text, language="text")


if __name__ == '__main__':
    main()