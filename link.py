import streamlit as st
import threading
import uuid
import time
import requests
import re
import random
import html
from urllib.parse import quote
from datetime import datetime, timedelta, timezone
from retrying import retry

# ==========================================
# 0. å…¨å±€é…ç½®ä¸ Secrets è¯»å–
# ==========================================
def get_secret(section, key, default=""):
    try:
        if section in st.secrets:
            return st.secrets[section].get(key, default)
        flat_key = f"{section}_{key}".upper()
        if flat_key in st.secrets:
            return st.secrets[flat_key]
    except: pass
    return default

q_img_url = get_secret("quark", "img_url")
b_img_url = get_secret("baidu", "img_url")

FIXED_IMAGE_CONFIG = {
    "quark": {"url": q_img_url, "enabled": bool(q_img_url and q_img_url.strip())},
    "baidu": {"url": b_img_url, "pwd": get_secret("baidu", "img_pwd"), "name": get_secret("baidu", "img_name", "å…¬ä¼—å·å…³æ³¨.jpg"), "enabled": bool(b_img_url and b_img_url.strip())}
}

QUARK_SAVE_PATH = "æ¥è‡ªï¼šåˆ†äº«/LinkChanger"
BAIDU_SAVE_PATH = "/æˆ‘çš„èµ„æº/LinkChanger"

# ==========================================
# 1. æ ¸å¿ƒï¼šåå°ä»»åŠ¡ç®¡ç†å™¨
# ==========================================
@st.cache_resource
class JobManager:
    def __init__(self):
        self.jobs = {} 

    def _cleanup_old_jobs(self):
        now = datetime.now()
        expired_ids = [jid for jid, job in self.jobs.items() 
                       if (now - job['created_at']).total_seconds() > 86400]
        for jid in expired_ids:
            del self.jobs[jid]

    def create_job(self):
        self._cleanup_old_jobs()
        job_id = str(uuid.uuid4())[:8]
        self.jobs[job_id] = {
            "status": "running",
            "logs": [],
            "result_text": "",
            "progress": {"current": 0, "total": 0},
            "created_at": datetime.now(),
            "summary": {}
        }
        return job_id

    def get_job(self, job_id):
        return self.jobs.get(job_id)

    def add_log(self, job_id, message, type="info"):
        if job_id in self.jobs:
            timestamp = (datetime.now(timezone.utc) + timedelta(hours=8)).strftime("%H:%M:%S")
            # çº¯æ–‡æœ¬æ—¥å¿—ï¼Œæœ€ç¨³å®š
            icon = "ğŸ”¹"
            if type == 'success': icon = "âœ…"
            elif type == 'error': icon = "âŒ"
            elif type == 'quark': icon = "â˜ï¸"
            elif type == 'baidu': icon = "ğŸ»"
            self.jobs[job_id]["logs"].append(f"{timestamp} {icon} {message}")

    def update_progress(self, job_id, current, total):
        if job_id in self.jobs:
            self.jobs[job_id]["progress"] = {"current": current, "total": total}

    def complete_job(self, job_id, final_text, summary):
        if job_id in self.jobs:
            self.jobs[job_id]["status"] = "done"
            self.jobs[job_id]["result_text"] = final_text
            self.jobs[job_id]["summary"] = summary

job_manager = JobManager()

# ==========================================
# 2. é¡µé¢é…ç½®ä¸â€œé˜²å¼¹â€æ ·å¼
# ==========================================
st.set_page_config(
    page_title="ç½‘ç›˜è½¬å­˜åŠ©æ‰‹",
    page_icon="ğŸ“‚",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ğŸ›¡ï¸ æ ¸å¿ƒä¿®å¤ï¼šæ³¨å…¥ meta æ ‡ç­¾ï¼Œç¦æ­¢æµè§ˆå™¨ç¿»è¯‘å’Œè‡ªåŠ¨è°ƒæ•´ï¼Œé˜²æ­¢ç ´å DOM å¯¼è‡´çº¢å±
st.markdown("""
    <meta name="google" content="notranslate">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <style>
    /* å¼ºåˆ¶ç¦æ­¢ç¿»è¯‘å±æ€§ */
    body { -webkit-font-smoothing: antialiased; }
    .stApp { touch-action: manipulation; }
    
    /* ç®€å•çš„æ ·å¼ä¼˜åŒ– */
    .block-container { padding-top: 1rem !important; padding-bottom: 3rem; }
    
    /* çŠ¶æ€ç‚¹ */
    .status-dot-green { color: #52c41a; font-weight: bold; }
    .status-dot-red { color: #ff4d4f; font-weight: bold; }
    .status-dot-gray { color: #d9d9d9; font-weight: bold; }
    
    /* è¿”å›é¡¶éƒ¨ */
    .back-to-top {
        position: fixed; bottom: 80px; right: 20px; width: 45px; height: 45px;
        background-color: #ff4b4b; border-radius: 50%;
        box-shadow: 0 4px 12px rgba(0,0,0,0.2); z-index: 999999;
        display: flex; align-items: center; justify-content: center;
        text-decoration: none; color: white; font-size: 20px; opacity: 0.8;
    }
    </style>
    <div id="top-anchor"></div>
""", unsafe_allow_html=True)

INVALID_CHARS_REGEX = re.compile(r'[^\u4e00-\u9fa5a-zA-Z0-9_\-\s]')

def get_time_diff(start_time):
    diff = time.time() - start_time
    return f"{diff:.2f}s"

def create_copy_button_html(text_to_copy: str):
    safe_text = json.dumps(text_to_copy)[1:-1]
    return f"""
    <div style="margin-top: 10px;">
        <button style="width:100%;padding:12px;background:#fff;border:1px solid #ddd;border-radius:8px;font-weight:bold;color:#333;cursor:pointer;" 
        onclick="navigator.clipboard.writeText('{safe_text}').then(()=>{{this.innerText='âœ… å·²å¤åˆ¶';this.style.color='green';setTimeout(()=>{{this.innerText='ğŸ“‹ ä¸€é”®å¤åˆ¶ç»“æœ';this.style.color='#333'}}, 2000)}})">
        ğŸ“‹ ä¸€é”®å¤åˆ¶ç»“æœ
        </button>
    </div>
    """

def sanitize_filename(name: str) -> str:
    if not name: return ""
    name = re.sub(r'[ã€ã€‘\[\]()]', ' ', name)
    clean_name = INVALID_CHARS_REGEX.sub('', name)
    return re.sub(r'\s+', ' ', clean_name).strip()

def extract_smart_folder_name(full_text: str, match_start: int) -> str:
    lookback_limit = max(0, match_start - 200)
    pre_text = full_text[lookback_limit:match_start]
    lines = pre_text.splitlines()
    candidate_name = ""
    for line in reversed(lines):
        clean_line = line.strip()
        if not clean_line: continue
        if re.match(r'^(ç™¾åº¦|é“¾æ¥|æå–ç |:|ï¼š|https?|å¤¸å…‹|pwd|code)*$', clean_line, re.IGNORECASE):
            continue
        clean_line = re.sub(r'(ç™¾åº¦|é“¾æ¥|æå–ç |:|ï¼š|pwd|å¤¸å…‹).*$', '', clean_line, flags=re.IGNORECASE).strip()
        if clean_line:
            candidate_name = clean_line
            break
    final_name = sanitize_filename(candidate_name)
    if not final_name or len(final_name) < 2:
        return f"Res_{int(time.time())}" 
    return final_name[:50]

def send_notification(bark_key, pushdeer_key, title, body):
    if bark_key:
        url = f"https://api.day.app/{bark_key}/{quote(title)}/{quote(body)}?icon=https://cdn-icons-png.flaticon.com/512/2991/2991110.png"
        try: requests.get(url, timeout=5)
        except: pass
    if pushdeer_key:
        url = "https://api2.pushdeer.com/message/push"
        params = {"pushkey": pushdeer_key, "text": title, "desp": body, "type": "markdown"}
        try: requests.get(url, params=params, timeout=5)
        except: pass

# ==========================================
# 3. å¼•æ“ç±» (å¤¸å…‹ & ç™¾åº¦)
# ==========================================
class QuarkEngine:
    def __init__(self, cookies: str):
        self.headers = {
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'cookie': cookies,
            'origin': 'https://pan.quark.cn',
            'referer': 'https://pan.quark.cn/',
        }
        self.client = httpx.AsyncClient(timeout=45.0, headers=self.headers, follow_redirects=True)

    async def close(self):
        await self.client.aclose()

    def _params(self):
        return {'pr': 'ucpro', 'fr': 'pc', '__dt': random.randint(100, 9999), '__t': int(time.time() * 1000)}

    async def check_login(self):
        try:
            r = await self.client.get('https://pan.quark.cn/account/info', params=self._params())
            data = r.json()
            if (data.get('code') == 0 or data.get('code') == 'OK') and data.get('data'):
                return data['data'].get('nickname', 'ç”¨æˆ·')
        except: pass
        return None

    async def get_folder_id(self, path: str):
        parts = path.split('/')
        curr_id = '0'
        for part in parts:
            if not part: continue
            found = False
            params = self._params()
            params.update({'pdir_fid': curr_id, '_page': 1, '_size': 50, '_fetch_total': 'false', '_sort': 'file_type:asc,updated_at:desc'})
            try:
                r = await self.client.get('https://drive-pc.quark.cn/1/clouddrive/file/sort', params=params)
                for item in r.json().get('data', {}).get('list', []):
                    if item['file_name'] == part and item['dir']:
                        curr_id = item['fid']
                        found = True
                        break
            except: pass
            if not found: return None 
        return curr_id

    async def process_url(self, url: str, target_fid: str, is_inject: bool = False):
        try:
            if '/s/' not in url: return None, "æ ¼å¼é”™è¯¯", None
            pwd_id = url.split('/s/')[-1].split('?')[0].split('#')[0]
            match = re.search(r'[?&]pwd=([a-zA-Z0-9]+)', url)
            passcode = match.group(1) if match else ""
        except: return None, "è§£æå¼‚å¸¸", None

        try:
            r = await self.client.post("https://drive-pc.quark.cn/1/clouddrive/share/sharepage/token", 
                                     json={"pwd_id": pwd_id, "passcode": passcode}, params=self._params())
            stoken = r.json().get('data', {}).get('stoken')
            if not stoken: return None, "æå–ç å¤±æ•ˆ", None
        except: return None, "Tokenè¯·æ±‚å¤±è´¥", None

        params = self._params()
        params.update({"pwd_id": pwd_id, "stoken": stoken, "pdir_fid": "0", "_page": 1, "_size": 50})
        try:
            r = await self.client.get("https://drive-pc.quark.cn/1/clouddrive/share/sharepage/detail", params=params)
            items = r.json().get('data', {}).get('list', [])
            if not items: return None, "ç©ºåˆ†äº«", None
            source_fids = [i['fid'] for i in items]
            source_tokens = [i['share_fid_token'] for i in items]
            first_name = items[0]['file_name']
        except: return None, "è·å–è¯¦æƒ…å¤±è´¥", None

        save_data = {"fid_list": source_fids, "fid_token_list": source_tokens, "to_pdir_fid": target_fid, 
                     "pwd_id": pwd_id, "stoken": stoken, "pdir_fid": "0", "scene": "link"}
        try:
            r = await self.client.post("https://drive.quark.cn/1/clouddrive/share/sharepage/save", json=save_data, params=self._params())
            if r.json().get('code') not in [0, 'OK']: return None, f"è½¬å­˜å¤±è´¥: {r.json().get('message')}", None
            task_id = r.json().get('data', {}).get('task_id')
        except: return None, "è½¬å­˜è¯·æ±‚å¤±è´¥", None

        if is_inject: return "INJECT_OK", "æ¤å…¥æˆåŠŸ", None

        for _ in range(8):
            await asyncio.sleep(1)
            try:
                params = self._params()
                params['task_id'] = task_id
                r = await self.client.get("https://drive-pc.quark.cn/1/clouddrive/task", params=params)
                if r.json().get('data', {}).get('status') == 2: break
            except: pass

        await asyncio.sleep(1.5)
        new_fid = None
        params = self._params()
        params.update({'pdir_fid': target_fid, '_page': 1, '_size': 20, '_sort': 'updated_at:desc'})
        try:
            r = await self.client.get('https://drive-pc.quark.cn/1/clouddrive/file/sort', params=params)
            for item in r.json().get('data', {}).get('list', []):
                if item['file_name'] == first_name: 
                    new_fid = item['fid']; break
            if not new_fid and r.json().get('data', {}).get('list'):
                new_fid = r.json()['data']['list'][0]['fid']
        except: pass
        
        if not new_fid: return None, "âœ… å·²å­˜å…¥ç½‘ç›˜ (ä½†æ— æ³•è·å–æ–‡ä»¶IDï¼Œæœªåˆ†äº«)", None

        share_data = {"fid_list": [new_fid], "title": first_name, "url_type": 1, "expired_type": 1}
        try:
            r = await self.client.post("https://drive-pc.quark.cn/1/clouddrive/share", json=share_data, params=self._params())
            res = r.json()
            if res.get('code') != 0 and res.get('code') != 'OK':
                return None, f"âœ… å·²å­˜å…¥ç½‘ç›˜ (ä½†åˆ†äº«è¢«æ‹¦æˆª: {res.get('message')})", None
                
            share_task_id = res.get('data', {}).get('task_id')
            await asyncio.sleep(0.5)
            params = self._params()
            params.update({'task_id': share_task_id, 'retry_index': 0})
            r = await self.client.get("https://drive-pc.quark.cn/1/clouddrive/task", params=params)
            share_id = r.json().get('data', {}).get('share_id')
            
            r = await self.client.post("https://drive-pc.quark.cn/1/clouddrive/share/password", json={"share_id": share_id}, params=self._params())
            return r.json()['data']['share_url'], "æˆåŠŸ", new_fid
        except: return None, "âœ… å·²å­˜å…¥ç½‘ç›˜ (ä½†åˆ†äº«åˆ›å»ºå¼‚å¸¸)", None

class BaiduEngine:
    def __init__(self, cookies: str):
        self.s = requests.Session()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',
            'Referer': 'https://pan.baidu.com',
            'Cookie': "".join(cookies.split())
        }
        self.bdstoken = ''
        requests.packages.urllib3.disable_warnings()

    def update_cookie_bdclnd(self, bdclnd):
        current = dict(i.split('=', 1) for i in self.headers['Cookie'].split(';') if '=' in i)
        current['BDCLND'] = bdclnd
        self.headers['Cookie'] = ';'.join([f'{k}={v}' for k,v in current.items()])

    @retry(stop_max_attempt_number=2)
    def init_token(self):
        url = 'https://pan.baidu.com/api/gettemplatevariable'
        r = self.s.get(url, params={'fields': '["bdstoken","token","uk","isdocuser"]'}, headers=self.headers, verify=False)
        if r.json().get('errno') == 0:
            self.bdstoken = r.json()['result']['bdstoken']
            return True
        return False

    def check_dir_exists(self, path):
        if not path.startswith("/"): path = "/" + path
        try:
            r = self.s.get('https://pan.baidu.com/api/list', params={'dir': path, 'bdstoken': self.bdstoken, 'start': 0, 'limit': 1}, headers=self.headers, verify=False)
            return r.json().get('errno') == 0
        except: return False

    def create_dir(self, path):
        if not path.startswith("/"): path = "/" + path
        try:
            self.s.post('https://pan.baidu.com/api/create', params={'a': 'commit', 'bdstoken': self.bdstoken}, 
                        data={'path': path, 'isdir': 1, 'block_list': '[]'}, headers=self.headers, verify=False)
        except: pass

    def process_url(self, url_info: dict, root_path: str, is_inject: bool = False):
        url = url_info['url']
        pwd = url_info['pwd']
        clean_url = url.split('?')[0]
        folder_name = url_info.get('name', 'Temp')

        try:
            # 1. Verify
            if pwd:
                surl = re.search(r'(?:surl=|/s/1|/s/)([\w\-]+)', clean_url)
                if not surl: return None, "URLæ ¼å¼é”™è¯¯", None
                r = self.s.post('https://pan.baidu.com/share/verify', 
                                params={'surl': surl.group(1), 't': int(time.time()*1000), 'bdstoken': self.bdstoken, 'channel': 'chunlei', 'web': 1, 'clienttype': 0},
                                data={'pwd': pwd, 'vcode': '', 'vcode_str': ''}, headers=self.headers, verify=False)
                if r.json()['errno'] == 0:
                    self.update_cookie_bdclnd(r.json()['randsk'])
                else:
                    return None, "æå–ç é”™è¯¯", None

            # 2. Get FSID
            content = self.s.get(clean_url, headers=self.headers, verify=False).text
            try:
                shareid = re.search(r'"shareid":(\d+?),', content).group(1)
                uk = re.search(r'"share_uk":"(\d+?)",', content).group(1)
                fs_id_list = re.findall(r'"fs_id":(\d+?),', content)
                if not fs_id_list: return None, "æ— æ–‡ä»¶", None
            except: return None, "é¡µé¢è§£æå¤±è´¥", None

            # 3. Path
            if is_inject:
                save_path = root_path
            else:
                safe_suffix = ''.join(random.choices(string.ascii_letters + string.digits, k=4))
                final_folder = f"{folder_name}_{safe_suffix}"
                save_path = f"{root_path}/{final_folder}"
                self.create_dir(save_path) 

            # 4. Transfer
            try:
                r = self.s.post('https://pan.baidu.com/share/transfer', 
                                params={'shareid': shareid, 'from': uk, 'bdstoken': self.bdstoken},
                                data={'fsidlist': f"[{','.join(fs_id_list)}]", 'path': save_path}, 
                                headers=self.headers, verify=False, timeout=20)
                res = r.json()
            except requests.exceptions.RequestException:
                return None, "è½¬å­˜è¯·æ±‚è¶…æ—¶(æ–‡ä»¶å¯èƒ½è¿‡å¤§)", None

            if res.get('errno') == 12: 
                 if is_inject: return "INJECT_OK", "æ–‡ä»¶å·²å­˜åœ¨", save_path
                 return None, "è½¬å­˜å¤±è´¥(æ–‡ä»¶å·²å­˜åœ¨)", None
            
            if res.get('errno') != 0: 
                errno = res.get('errno')
                err_msg = f"è½¬å­˜å¤±è´¥({errno})"
                if errno == -10: err_msg = "å®¹é‡ä¸è¶³æˆ–æ–‡ä»¶æ•°è¶…é™"
                elif errno == -33: err_msg = "æ–‡ä»¶æ•°è¶…å‡ºé™åˆ¶(éä¼šå‘˜500)"
                elif errno == 4: err_msg = "æ–‡ä»¶è·¯å¾„æ— æ•ˆæˆ–åŒ…å«è¿è§„å†…å®¹(errno:4)"
                return None, err_msg, None

            if is_inject: return "INJECT_OK", "æˆåŠŸ", save_path

            # 5. Share
            r = self.s.get('https://pan.baidu.com/api/list', params={'dir': root_path, 'bdstoken': self.bdstoken}, headers=self.headers, verify=False)
            target_fsid = None
            for item in r.json().get('list', []):
                if item['server_filename'] == final_folder:
                    target_fsid = item['fs_id']; break
            
            if not target_fsid: return None, "âœ… å·²å­˜å…¥ç½‘ç›˜ (è·å–ç›®å½•å¤±è´¥)", None

            new_pwd = ''.join(random.choices(string.ascii_letters + string.digits, k=4))
            r = self.s.post('https://pan.baidu.com/share/set', 
                            params={'bdstoken': self.bdstoken, 'channel': 'chunlei', 'clienttype': 0, 'web': 1},
                            data={'period': 0, 'pwd': new_pwd, 'fid_list': f'[{target_fsid}]', 'schannel': 4}, headers=self.headers, verify=False)
            
            if r.json()['errno'] == 0:
                return f"{r.json()['link']}?pwd={new_pwd}", "æˆåŠŸ", save_path 
            return None, "âœ… å·²å­˜å…¥ç½‘ç›˜ (åˆ†äº«å¤±è´¥)", None

        except Exception as e:
            return None, f"å‘ç”Ÿå¼‚å¸¸: {str(e)[:20]}...", None

# ==========================================
# 5. æ ¸å¿ƒï¼šåå°çº¿ç¨‹ Worker
# ==========================================
def worker_thread(job_id, input_text, quark_cookie, baidu_cookie, bark_key, pushdeer_key):
    
    async def async_worker():
        start_time = datetime.now()
        final_text = input_text
        success_count = 0
        current_idx = 0
        
        quark_regex = re.compile(r'(https://pan\.quark\.cn/s/[a-zA-Z0-9]+(?:\?pwd=[a-zA-Z0-9]+)?)')
        baidu_regex = re.compile(r'(https?://pan\.baidu\.com/s/[a-zA-Z0-9_\-]+(?:\?pwd=[a-zA-Z0-9]+)?)')
        q_matches = list(quark_regex.finditer(input_text))
        b_matches = list(baidu_regex.finditer(input_text))
        total_tasks = len(q_matches) + len(b_matches)
        
        job_manager.update_progress(job_id, 0, total_tasks)
        
        q_engine = QuarkEngine(quark_cookie) if q_matches else None
        b_engine = BaiduEngine(baidu_cookie) if b_matches else None

        try:
            # --- å¤¸å…‹ ---
            if q_matches:
                if not quark_cookie: 
                    job_manager.add_log(job_id, "å¤¸å…‹ï¼šæœªé…ç½®Cookieï¼Œè·³è¿‡", "error")
                else:
                    job_manager.add_log(job_id, "å¼€å§‹å¤„ç†å¤¸å…‹é“¾æ¥...", "quark")
                    t0 = time.time()
                    user = await q_engine.check_login()
                    if not user: 
                        job_manager.add_log(job_id, f"ç™»å½•å¤±è´¥ ({get_time_diff(t0)})", "error")
                    else:
                        job_manager.add_log(job_id, f"ç™»å½•æˆåŠŸ: {user}", "success")
                        t0 = time.time()
                        root_fid = await q_engine.get_folder_id(QUARK_SAVE_PATH)
                        if not root_fid: 
                            job_manager.add_log(job_id, "ç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º...", "error")
                        else:
                            for match in q_matches:
                                current_idx += 1
                                raw_url = match.group(1)
                                job_manager.add_log(job_id, f"å¤„ç†ä¸­: {raw_url}", "quark")
                                job_manager.update_progress(job_id, current_idx, total_tasks)
                                
                                t_task = time.time()
                                new_url, msg, new_fid = await q_engine.process_url(raw_url, root_fid)
                                t_task_end = get_time_diff(t_task)
                                
                                if new_url:
                                    log_msg = f"è½¬å­˜æˆåŠŸ ({t_task_end})"
                                    if FIXED_IMAGE_CONFIG['quark']['enabled'] and new_fid:
                                        t_img = time.time()
                                        res_url, res_msg, _ = await q_engine.process_url(FIXED_IMAGE_CONFIG['quark']['url'], new_fid, is_inject=True)
                                        if res_url == "INJECT_OK": log_msg += f" + å›¾ç‰‡æ¤å…¥"
                                    
                                    job_manager.add_log(job_id, log_msg, "success")
                                    final_text = final_text.replace(raw_url, new_url)
                                    success_count += 1
                                else:
                                    job_manager.add_log(job_id, f"{msg} ({t_task_end})", "error")

                                await asyncio.sleep(random.uniform(2, 4))

            # --- ç™¾åº¦ ---
            if b_matches:
                if not baidu_cookie: 
                    job_manager.add_log(job_id, "ç™¾åº¦ï¼šæœªé…ç½®Cookieï¼Œè·³è¿‡", "error")
                else:
                    job_manager.add_log(job_id, "å¼€å§‹å¤„ç†ç™¾åº¦é“¾æ¥...", "baidu")
                    t0 = time.time()
                    if not b_engine.init_token(): 
                        job_manager.add_log(job_id, f"ç™»å½•å¤±è´¥ ({get_time_diff(t0)})", "error")
                    else:
                        job_manager.add_log(job_id, "ç™»å½•æˆåŠŸ", "success")
                        if not b_engine.check_dir_exists(BAIDU_SAVE_PATH): b_engine.create_dir(BAIDU_SAVE_PATH)
                        
                        for match in b_matches:
                            current_idx += 1
                            raw_url = match.group(1)
                            pwd_match = re.search(r'(?:\?pwd=|&pwd=|\s+|æå–ç [:ï¼š]?\s*)([a-zA-Z0-9]{4})', match.group(0))
                            pwd = pwd_match.group(1) if pwd_match else ""
                            
                            job_manager.add_log(job_id, f"å¤„ç†ä¸­: {raw_url}", "baidu")
                            job_manager.update_progress(job_id, current_idx, total_tasks)
                            
                            t_task = time.time()
                            name = extract_smart_folder_name(input_text, match.start())
                            new_url, msg, new_dir_path = b_engine.process_url({'url': raw_url, 'pwd': pwd, 'name': name}, BAIDU_SAVE_PATH)
                            t_task_end = get_time_diff(t_task)
                            
                            if new_url:
                                log_msg = f"è½¬å­˜æˆåŠŸ ({t_task_end})"
                                if FIXED_IMAGE_CONFIG['baidu']['enabled'] and new_dir_path:
                                    t_img = time.time()
                                    img_res_url, img_msg, _ = b_engine.process_url({'url': FIXED_IMAGE_CONFIG['baidu']['url'], 'pwd': FIXED_IMAGE_CONFIG['baidu']['pwd']}, new_dir_path, is_inject=True)
                                    if img_res_url == "INJECT_OK": log_msg += f" + å›¾ç‰‡æ¤å…¥"

                                job_manager.add_log(job_id, log_msg, "success")
                                final_text = final_text.replace(raw_url, new_url)
                                success_count += 1
                            else:
                                job_manager.add_log(job_id, f"{msg} ({t_task_end})", "error")

                            time.sleep(random.uniform(2, 4))

        finally:
            if q_engine: await q_engine.close()
            duration_obj = datetime.now() - start_time
            duration_str = str(duration_obj)[:-4] if len(str(duration_obj)) > 4 else str(duration_obj)
            summary = {"success": success_count, "total": total_tasks, "duration": str(duration_obj)}
            job_manager.complete_job(job_id, final_text, summary)
            
            if bark_key or pushdeer_key:
                body_msg = f"æˆåŠŸ: {success_count}/{total_tasks} | è€—æ—¶: {duration_str}"
                title_msg = "âœ… è½¬å­˜å®Œæˆ" if success_count > 0 else "âŒ è½¬å­˜ç»“æŸ(æ— æˆåŠŸ)"
                send_notification(bark_key, pushdeer_key, title_msg, body_msg)

    asyncio.run(async_worker())

# ==========================================
# 6. ä¸»é€»è¾‘ (å‰ç«¯ UI)
# ==========================================
@st.cache_data(ttl=300) 
def check_cookies_validity(q_c, b_c):
    status = {"quark": False, "baidu": False}
    if q_c:
        try:
            headers = {'user-agent': 'Mozilla/5.0', 'cookie': q_c, 'referer': 'https://pan.quark.cn/'}
            params = {'pr': 'ucpro', 'fr': 'pc', '__dt': random.randint(100, 9999)}
            r = requests.get('https://pan.quark.cn/account/info', headers=headers, params=params, timeout=5)
            if (r.json().get('code') in [0, 'OK']) and r.json().get('data'): status["quark"] = True
        except: pass
    if b_c:
        try:
            b_eng = BaiduEngine(b_c)
            if b_eng.init_token(): status["baidu"] = True
        except: pass
    return status

def check_password():
    TARGET_PWD = get_secret("general", "app_password", "")
    if not TARGET_PWD or not TARGET_PWD.strip(): return True
    if "password_correct" not in st.session_state: st.session_state.password_correct = False
    if not st.session_state.password_correct:
        st.title("ğŸ”’ è®¿é—®å—é™")
        pwd = st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
        if st.button("è§£é”"):
            if pwd == TARGET_PWD:
                st.session_state.password_correct = True
                st.rerun()
            else:
                st.error("å¯†ç é”™è¯¯")
        return False
    return True

def main():
    if not check_password(): return

    st.title("ç½‘ç›˜è½¬å­˜åŠ©æ‰‹")
    
    bark_key = get_secret("general", "bark_key")
    pushdeer_key = get_secret("general", "pushdeer_key")
    q_c = get_secret("quark", "cookie")
    b_c = get_secret("baidu", "cookie")
    cookie_status = check_cookies_validity(q_c, b_c)

    with st.sidebar:
        st.header("âš™ï¸ çŠ¶æ€ç›‘æ§")
        if not q_c: st.markdown("âšª **å¤¸å…‹**: æœªé…ç½®")
        elif cookie_status["quark"]: st.markdown("ğŸŸ¢ **å¤¸å…‹**: æœ‰æ•ˆ")
        else: st.markdown("ğŸ”´ **å¤¸å…‹**: å·²å¤±æ•ˆ")
            
        if not b_c: st.markdown("âšª **ç™¾åº¦**: æœªé…ç½®")
        elif cookie_status["baidu"]: st.markdown("ğŸŸ¢ **ç™¾åº¦**: æœ‰æ•ˆ")
        else: st.markdown("ğŸ”´ **ç™¾åº¦**: å·²å¤±æ•ˆ")

        st.divider()
        if FIXED_IMAGE_CONFIG['quark']['enabled']: st.success("ğŸ–¼ï¸ å¤¸å…‹æ¤å…¥: å¼€å¯")
        else: st.caption("âšª å¤¸å…‹æ¤å…¥: å…³é—­")
        
        if FIXED_IMAGE_CONFIG['baidu']['enabled']: st.success("ğŸ–¼ï¸ ç™¾åº¦æ¤å…¥: å¼€å¯")
        else: st.caption("âšª ç™¾åº¦æ¤å…¥: å…³é—­")
        
        if bark_key or pushdeer_key: st.info("ğŸ“¢ æ¶ˆæ¯æ¨é€: å¼€å¯")

    query_params = st.query_params
    current_job_id = query_params.get("job_id", None)

    if not current_job_id:
        st.info("ğŸ’¡ æç¤ºï¼šåå°è‡ªåŠ¨è¿è¡Œï¼Œä»»åŠ¡å¼€å§‹åå¯å…³é—­ç½‘é¡µã€‚")
        # ğŸŸ¢ è®¾ç½® translate=no é˜²æ­¢æµè§ˆå™¨ç¿»è¯‘å¯¼è‡´ DOM é”™ä¹±
        st.markdown('<div translate="no">', unsafe_allow_html=True)
        input_text = st.text_area("ğŸ“ ç²˜è´´é“¾æ¥...", height=150, key="link_input")
        st.markdown('</div>', unsafe_allow_html=True)
        
        if st.button("ğŸš€ å¼€å§‹è½¬å­˜", type="primary", use_container_width=True):
            if not input_text.strip(): st.toast("è¯·è¾“å…¥å†…å®¹", icon="âš ï¸"); return
            if not cookie_status["quark"] and not cookie_status["baidu"]:
                 st.error("âŒ æ‰€æœ‰è´¦å· Cookie å‡å·²å¤±æ•ˆ"); return
            new_job_id = job_manager.create_job()
            t = threading.Thread(target=worker_thread, args=(new_job_id, input_text, q_c, b_c, bark_key, pushdeer_key))
            t.start()
            st.query_params["job_id"] = new_job_id
            st.rerun()
    else:
        job_data = job_manager.get_job(current_job_id)
        if not job_data:
            st.error("âŒ ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ")
            if st.button("ğŸ”™ è¿”å›"):
                st.query_params.clear()
                st.rerun()
        else:
            status = job_data['status']
            if status == "running":
                st.markdown(f"### ğŸ”„ è¿è¡Œä¸­... <span style='color:blue'>RUNNING</span>", unsafe_allow_html=True)
                st.caption(f"ID: `{current_job_id}`")
            else:
                st.markdown("### âœ… å·²å®Œæˆ")

            prog = job_data['progress']
            if prog['total'] > 0:
                st.progress(prog['current'] / prog['total'], text=f"è¿›åº¦: {prog['current']} / {prog['total']}")

            # ğŸ›¡ï¸ æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨ st.text æ˜¾ç¤ºæ—¥å¿—ï¼Œå¹¶åŒ…è£¹åœ¨ç¦æ­¢ç¿»è¯‘å®¹å™¨ä¸­
            st.markdown('<div translate="no">', unsafe_allow_html=True)
            st.markdown("##### ğŸ“œ æ‰§è¡Œæ—¥å¿—")
            if job_data['logs']:
                logs_text = "\n".join(job_data['logs'])
                # st.text æ˜¯æœ€æœ€åŸºç¡€çš„çº¯æ–‡æœ¬ç»„ä»¶ï¼Œæ²¡æœ‰è¯­æ³•é«˜äº®ï¼Œæ¸²æŸ“æå¿«
                st.text(logs_text)
            else:
                st.info("æš‚æ— æ—¥å¿—...")
            st.markdown('</div>', unsafe_allow_html=True)

            if status == "done":
                res_text = job_data['result_text']
                summary = job_data['summary']
                duration = str(summary.get('duration', '0s')).split('.')[0]
                
                st.divider()
                st.success(f"âœ… æˆåŠŸ: {summary.get('success', 0)} / {summary.get('total', 0)}  |  â± è€—æ—¶: {duration}")
                
                st.markdown('<div translate="no">', unsafe_allow_html=True)
                st.markdown("##### â¬‡ï¸ æœ€ç»ˆç»“æœ (ç‚¹å‡»å³ä¸Šè§’å¤åˆ¶)")
                st.code(res_text, language="text")
                st.markdown('</div>', unsafe_allow_html=True)
                
                if st.button("ğŸ—‘ï¸ å¼€å§‹æ–°ä»»åŠ¡", use_container_width=True):
                    st.query_params.clear()
                    st.rerun()
            else:
                # ğŸŸ¡ ä¿æŒè¾ƒæ…¢çš„åˆ·æ–°é¢‘ç‡
                time.sleep(3) 
                st.rerun()

# è¿”å›é¡¶éƒ¨æŒ‰é’®
st.markdown('<a href="#top-anchor" class="back-to-top" title="Top">â¬†ï¸</a>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()
